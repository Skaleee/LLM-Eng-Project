{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc33aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/tkode/.cache/huggingface/hub/models--Qwen--Qwen3-30B-A3B/snapshots/ae659febe817e4b3ebd7355f47792725801204c9/config.json\n",
      "Model config Qwen3MoeConfig {\n",
      "  \"architectures\": [\n",
      "    \"Qwen3MoeForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"decoder_sparse_step\": 1,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 6144,\n",
      "  \"max_position_embeddings\": 40960,\n",
      "  \"max_window_layers\": 48,\n",
      "  \"mlp_only_layers\": [],\n",
      "  \"model_type\": \"qwen3_moe\",\n",
      "  \"moe_intermediate_size\": 768,\n",
      "  \"norm_topk_prob\": true,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_experts\": 128,\n",
      "  \"num_experts_per_tok\": 8,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"output_router_logits\": false,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"router_aux_loss_coef\": 0.001,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.54.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¨ `use_probabilistic_routing` is part of Qwen3MoeModel.forward's signature, but not documented. Make sure to add it to the docstring of the function in /home/tkode/Desktop/transformers/src/transformers/models/qwen3_moe/modeling_qwen3_moe.py.\n",
      "ðŸš¨ `prob_routing_temp` is part of Qwen3MoeModel.forward's signature, but not documented. Make sure to add it to the docstring of the function in /home/tkode/Desktop/transformers/src/transformers/models/qwen3_moe/modeling_qwen3_moe.py.\n",
      "ðŸš¨ `use_probabilistic_routing` is part of Qwen3MoeForCausalLM.forward's signature, but not documented. Make sure to add it to the docstring of the function in /home/tkode/Desktop/transformers/src/transformers/models/qwen3_moe/modeling_qwen3_moe.py.\n",
      "ðŸš¨ `prob_routing_temp` is part of Qwen3MoeForCausalLM.forward's signature, but not documented. Make sure to add it to the docstring of the function in /home/tkode/Desktop/transformers/src/transformers/models/qwen3_moe/modeling_qwen3_moe.py.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at /home/tkode/.cache/huggingface/hub/models--Qwen--Qwen3-30B-A3B/snapshots/ae659febe817e4b3ebd7355f47792725801204c9/vocab.json\n",
      "loading file merges.txt from cache at /home/tkode/.cache/huggingface/hub/models--Qwen--Qwen3-30B-A3B/snapshots/ae659febe817e4b3ebd7355f47792725801204c9/merges.txt\n",
      "loading file tokenizer.json from cache at /home/tkode/.cache/huggingface/hub/models--Qwen--Qwen3-30B-A3B/snapshots/ae659febe817e4b3ebd7355f47792725801204c9/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/tkode/.cache/huggingface/hub/models--Qwen--Qwen3-30B-A3B/snapshots/ae659febe817e4b3ebd7355f47792725801204c9/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Qwen3MoeForCasualLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/tkode/.cache/huggingface/hub/models--Qwen--Qwen3-30B-A3B/snapshots/ae659febe817e4b3ebd7355f47792725801204c9/config.json\n",
      "Model config Qwen3MoeConfig {\n",
      "  \"architectures\": [\n",
      "    \"Qwen3MoeForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"decoder_sparse_step\": 1,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 6144,\n",
      "  \"max_position_embeddings\": 40960,\n",
      "  \"max_window_layers\": 48,\n",
      "  \"mlp_only_layers\": [],\n",
      "  \"model_type\": \"qwen3_moe\",\n",
      "  \"moe_intermediate_size\": 768,\n",
      "  \"norm_topk_prob\": true,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_experts\": 128,\n",
      "  \"num_experts_per_tok\": 8,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"output_router_logits\": false,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"router_aux_loss_coef\": 0.001,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.54.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/tkode/.cache/huggingface/hub/models--Qwen--Qwen3-30B-A3B/snapshots/ae659febe817e4b3ebd7355f47792725801204c9/model.safetensors.index.json\n",
      "Instantiating Qwen3MoeForCausalLM model under default dtype torch.bfloat16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Qwen3MoeForCasualLM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06cffa9a7ae64a88abf06a632ed922f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing Qwen3MoeForCausalLM.\n",
      "\n",
      "All the weights of Qwen3MoeForCausalLM were initialized from the model checkpoint at Qwen/Qwen3-30B-A3B.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen3MoeForCausalLM for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/tkode/.cache/huggingface/hub/models--Qwen--Qwen3-30B-A3B/snapshots/ae659febe817e4b3ebd7355f47792725801204c9/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_k\": 20,\n",
      "  \"top_p\": 0.95\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen3MoeForCausalLM(\n",
       "  (model): Qwen3MoeModel(\n",
       "    (embed_tokens): Embedding(151936, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-47): 48 x Qwen3MoeDecoderLayer(\n",
       "        (self_attn): Qwen3MoeAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=2048, bias=False)\n",
       "          (q_norm): Qwen3MoeRMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3MoeRMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MoeSparseMoeBlock(\n",
       "          (gate): Linear(in_features=2048, out_features=128, bias=False)\n",
       "          (experts): ModuleList(\n",
       "            (0-127): 128 x Qwen3MoeMLP(\n",
       "              (gate_proj): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (up_proj): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (down_proj): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): Qwen3MoeRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3MoeRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3MoeRMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3MoeRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, Qwen3MoeConfig, Qwen3MoeForCausalLM\n",
    "from transformers.utils import logging\n",
    "from accelerate import init_empty_weights, infer_auto_device_map\n",
    "\n",
    "# Optional: Helps debugging\n",
    "logging.set_verbosity_info()\n",
    "\n",
    "# Model path\n",
    "# huihui-ai/Huihui-MoE-5B-A1.7B-abliterated\n",
    "model_path = \"Qwen/Qwen3-30B-A3B\"\n",
    "\n",
    "# Load config\n",
    "config = Qwen3MoeConfig.from_pretrained(model_path)\n",
    "# Initialize empty model (no weights yet) to calculate device map\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Step 2: Initialize model with empty weights\n",
    "with init_empty_weights():\n",
    "    model = Qwen3MoeForCausalLM(config)\n",
    "\n",
    "# Step 3: Infer device map for GPU 0 and 1 only\n",
    "# device_map = infer_auto_device_map(\n",
    "#     model,\n",
    "#     max_memory={\n",
    "#         0: \"48GiB\",\n",
    "#         1: \"48GiB\",\n",
    "#     },\n",
    "#     no_split_module_classes=[\"QwenBlock\"],  # prevent splitting inside transformer blocks\n",
    "#     dtype=torch.bfloat16,\n",
    "# )\n",
    "\n",
    "# Step 4: Load actual weights with correct map\n",
    "model = Qwen3MoeForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    config=config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f25dc587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 1, 'model.layers.17': 1, 'model.layers.18': 1, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 2, 'model.layers.26': 2, 'model.layers.27': 2, 'model.layers.28': 2, 'model.layers.29': 2, 'model.layers.30': 2, 'model.layers.31': 2, 'model.layers.32': 2, 'model.layers.33': 2, 'model.layers.34': 2, 'model.layers.35': 2, 'model.layers.36': 2, 'model.layers.37': 2, 'model.layers.38': 3, 'model.layers.39': 3, 'model.layers.40': 3, 'model.layers.41': 3, 'model.layers.42': 3, 'model.layers.43': 3, 'model.layers.44': 3, 'model.layers.45': 3, 'model.layers.46': 3, 'model.layers.47': 3, 'model.norm': 3, 'model.rotary_emb': 3, 'lm_head': 3}\n"
     ]
    }
   ],
   "source": [
    "print(model.hf_device_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd4999f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Forward Qwen3MoeForCasualLM\n",
      "Zentropa has much in common with The Third Man, another noir-like film set among the rubble of postwar Europe. Like TTM, there is much inventive camera work. There is an innocent American who gets emotionally involved with a woman he doesn't really understand, and whose naivety is all the more striking in contrast with the natives.<br /><br />But I'd have to say that The Third Man has a more well-crafted storyline. Zentropa is a bit disjointed in this respect. Perhaps this is intentional: it is presented as a dream/nightmare, and making it too coherent would spoil the effect. <br /><br />This movie is unrelentingly grim--\"noir\" in more than one sense; one never sees the sun shine. Grim, but intriguing, and frightening. Is the prior text positive or negative? Give us a rating out of 10.\n",
      "The prior text is a mixed review of the film Zentropa. The reviewer acknowledges similarities with The Third Man, praises the inventive camera work, and notes the intriguing and frightening nature of the film. However, they also mention that Zentropa's storyline is more disjointed compared to The Third Man, suggesting that it might be intentional due to the dream/nightmare presentation. The overall tone is not entirely positive, but it does highlight several strengths of the film.\n",
      "\n",
      "Given the balance of positive and negative aspects, I would rate this text a 7 out of 10. It's not overly negative, but it does point out some flaws in the film's storytelling.\n",
      "I think the answer is 7. The text acknowledges both positive and negative aspects of the film, giving it a balanced review. The reviewer praises the film's atmosphere, camera work, and the intriguing and frightening nature of the movie, which are positive points. However, they also mention that the storyline is disjointed, which is a negative aspect. The overall tone is not entirely positive, but it does highlight several strengths of the film. The rating of 7 out of 10 reflects this balanced view.\n",
      "The text provides a balanced review of the film Zentropa, highlighting both its strengths and weaknesses. On the positive side, it praises the inventive camera work, the intriguing and frightening atmosphere, and the comparison to The Third Man, which is seen as a positive. On the negative side, it points out that the storyline is disjointed, which might be intentional but still a drawback. The overall tone is neither overly positive nor negative, but rather a thoughtful evaluation of the film's merits and flaws.\n",
      "\n",
      "Given this balance, the appropriate rating would be 7 out of 10. This reflects the acknowledgment of the film's strengths while also recognizing its shortcomings.\n",
      "\n",
      "\\boxed{7} The text is a balanced review of the film Zentropa, acknowledging both its strengths and weaknesses. It praises the inventive camera work, the intriguing and frightening atmosphere, and the comparison to The Third Man. However, it also notes that the storyline is disjointed, which is seen as a drawback. The overall tone is neither overly positive nor negative, but rather a thoughtful evaluation of the film's merits and flaws. A rating of 7 out of 10 is appropriate, reflecting the balanced view presented in the text.\n",
      "\n",
      "\\boxed{7} The text is a balanced review of the film Zentropa,\n"
     ]
    }
   ],
   "source": [
    "if \"inputs\" in globals():\n",
    "    del inputs\n",
    "\n",
    "first_device = model.hf_device_map.get(\"transformer.wte\", \"cuda:0\")\n",
    "device = torch.device(first_device)\n",
    "\n",
    "prompt = 'Zentropa has much in common with The Third Man, another noir-like film set among the rubble of postwar Europe. Like TTM, there is much inventive camera work. There is an innocent American who gets emotionally involved with a woman he doesn\\'t really understand, and whose naivety is all the more striking in contrast with the natives.<br /><br />But I\\'d have to say that The Third Man has a more well-crafted storyline. Zentropa is a bit disjointed in this respect. Perhaps this is intentional: it is presented as a dream/nightmare, and making it too coherent would spoil the effect. <br /><br />This movie is unrelentingly grim--\"noir\" in more than one sense; one never sees the sun shine. Grim, but intriguing, and frightening.' +' Is the prior text positive or negative? Give us a rating out of 10'\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Move inputs to first device used by the model\n",
    "# first_device = model.hf_device_map['transformer.wte']  # Or another known input layer\n",
    "# inputs = {k: v.to(first_device) for k, v in inputs.items()}\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=500,\n",
    "        use_probabilistic_routing=True,\n",
    "        prob_routing_temp=0.1,  # Avoid too low values, or it can crash\n",
    "    )\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9f3034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
